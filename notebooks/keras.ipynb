{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, InputLayer, Activation\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 2) (2000, 2)\n"
     ]
    }
   ],
   "source": [
    "#MNIST Dataset Load\n",
    "\n",
    "# batch_size = 128\n",
    "# num_classes = 10\n",
    "# epochs = 10\n",
    "\n",
    "# (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# x_train = x_train.reshape(60000, 784)\n",
    "# x_test = x_test.reshape(10000, 784)\n",
    "# x_train = x_train.astype('float32')\n",
    "# x_test = x_test.astype('float32')\n",
    "# x_train /= 255\n",
    "# x_test /= 255\n",
    "# print(x_train.shape[0], 'train samples')\n",
    "# print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# # One hot conversion\n",
    "# y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "# y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import resample\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "n_samples = 2000\n",
    "#Play with different datasets.\n",
    "#feat, labels = datasets.make_classification(n_features=2, n_classes=2, n_redundant=0, n_informative=1, random_state=1, n_clusters_per_class=1, n_samples=n_samples)\n",
    "feat, labels = datasets.make_moons(n_samples=n_samples, noise=0.05)\n",
    "#feat, labels = datasets.make_circles(n_samples=400, factor=.3, noise=.05)\n",
    "#feat, labels = datasets.make_blobs(n_samples=n_samples)\n",
    "new_feat, new_labels = resample(feat, labels, n_samples=10000, replace=True)\n",
    "new_labels = to_categorical(new_labels, num_classes=2)\n",
    "\n",
    "#labels = labels.reshape([-1,1])\n",
    "#print(feat.shape, labels.shape)\n",
    "#((x,y) for zip(feat,labels) if labels==1)\n",
    "#feat_small = feat[np.where(labels==1)]\n",
    "# lab_small = np.zeros(feat_small.shape[0])\n",
    "# lab_small = to_categorical(lab_small, num_classes=1)\n",
    "# print(feat_small.shape, lab_small.shape)\n",
    "#feat_small, label = ((x,y) for x,y in zip(feat,labels) if y==1)\n",
    "\n",
    "#feat, labels = datasets.make_blobs(n_samples=n_samples)\n",
    "labels = to_categorical(labels, num_classes=2)\n",
    "print(feat.shape, labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 36\n",
      "Trainable params: 36\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "10000/10000 [==============================] - 1s 119us/step - loss: 0.6917 - acc: 0.5285\n",
      "Epoch 2/100\n",
      "10000/10000 [==============================] - 1s 67us/step - loss: 0.6637 - acc: 0.6014\n",
      "Epoch 3/100\n",
      "10000/10000 [==============================] - 1s 68us/step - loss: 0.5846 - acc: 0.6621\n",
      "Epoch 4/100\n",
      "10000/10000 [==============================] - 1s 71us/step - loss: 0.5548 - acc: 0.6797\n",
      "Epoch 5/100\n",
      "10000/10000 [==============================] - 1s 70us/step - loss: 0.5355 - acc: 0.6795\n",
      "Epoch 6/100\n",
      "10000/10000 [==============================] - 1s 83us/step - loss: 0.5189 - acc: 0.6856\n",
      "Epoch 7/100\n",
      "10000/10000 [==============================] - 1s 74us/step - loss: 0.5096 - acc: 0.6862\n",
      "Epoch 8/100\n",
      "10000/10000 [==============================] - 1s 68us/step - loss: 0.5006 - acc: 0.6879\n",
      "Epoch 9/100\n",
      "10000/10000 [==============================] - 1s 66us/step - loss: 0.4961 - acc: 0.6830\n",
      "Epoch 10/100\n",
      "10000/10000 [==============================] - 1s 83us/step - loss: 0.4956 - acc: 0.6837\n",
      "Epoch 11/100\n",
      "10000/10000 [==============================] - 1s 72us/step - loss: 0.4865 - acc: 0.6858\n",
      "Epoch 12/100\n",
      "10000/10000 [==============================] - 1s 77us/step - loss: 0.4866 - acc: 0.6874\n",
      "Epoch 13/100\n",
      " 9600/10000 [===========================>..] - ETA: 0s - loss: 0.4839 - acc: 0.6770"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-b981a483ca98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m                     \u001b[0;31m#batch_size=batch_size,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m#EPOCHS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                     verbose=1)\n\u001b[0m\u001b[1;32m     32\u001b[0m                     \u001b[0;31m#validation_data=(x_test, y_test),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                     \u001b[0;31m#callbacks=[tfcall])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.6/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1000\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.6/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.6/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1079\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m           \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m           \u001b[0mfeed_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubfeed_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m     \u001b[0;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.6/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mname\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    324\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;34m\"\"\"The string name of this tensor.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Operation was not named: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"%s:%d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "model = Sequential()\n",
    "\n",
    "###Model###\n",
    "model.add(Dense(2, input_dim=2, activation='relu'))\n",
    "model.add(Dense(2, input_dim=2, activation='relu'))\n",
    "model.add(keras.layers.add(model.layers[-1], model.layers[-1]))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(2, input_dim=2, activation='relu'))\n",
    "model.add(Dense(2, input_dim=2, activation='relu'))\n",
    "model.add(Dense(2, input_dim=2, activation='relu'))\n",
    "#model.add(Activation('tanh'))\n",
    "# model.add(Dense(2, input_dim=2))\n",
    "# model.add(Activation('tanh'))\n",
    "# model.add(Dense(2, input_dim=2))\n",
    "# model.add(Activation('tanh'))\n",
    "# model.add(Dense(2, input_dim=2))\n",
    "# model.add(Activation('tanh'))\n",
    "# model.add(Dense(2, input_dim=2))\n",
    "# model.add(Activation('tanh'))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "\n",
    "#tfcall = keras.callbacks.TensorBoard(log_dir='../plots/keras600newlogs', histogram_freq=1, write_graph=True)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer=Adam(), metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(new_feat, new_labels,\n",
    "                    #batch_size=batch_size,\n",
    "                    epochs=20, #EPOCHS\n",
    "                    verbose=1)\n",
    "                    #validation_data=(x_test, y_test),\n",
    "                    #callbacks=[tfcall])\n",
    "#score = model.evaluate(x_test, y_test, verbose=0)\n",
    "#print('Test loss:', score[0])\n",
    "#print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layer(inp, out, layer_array):\n",
    "    return K.function([layer_array.layers[inp].input], [layer_array.layers[out].output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first = get_layer(0, 0, model)\n",
    "# second = get_layer(0,2, model)\n",
    "# third = get_layer(0,4, model)\n",
    "# out1 = first([x_test])\n",
    "# out2 = second([x_test])\n",
    "# out3 = third([x_test])\n",
    "# print(out1[0].shape, out2[0].shape, out3[0].shape)\n",
    "\n",
    "activations = []\n",
    "for layer in range(len(model.layers)):\n",
    "    extract_func = get_layer(0,layer, model)\n",
    "    activations.append(extract_func([new_feat])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activations[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../scripts/')\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the format of your plot grid:\n",
      "[ (1,1) x1,y1 ]     [ (1,2) x2,y2 ]     [ (1,3) x3,y3 ]     [ (1,4) x4,y4 ]     [ (1,5) x5,y5 ]     [ (1,6) x6,y6 ]     [ (1,7) x7,y7 ]     [ (1,8) x8,y8 ]     [ (1,9) x9,y9 ]     [ (1,10) x10,y10 ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "morphs(activations, np.argmax(new_labels, axis=1), skip=1, last_layer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 2)\n"
     ]
    }
   ],
   "source": [
    "mesh = [(a,b) for a in np.arange(-10, 10, 1) for b in np.arange(-10, 10, 1)]\n",
    "mesh = np.asarray(mesh)\n",
    "print(mesh.shape)\n",
    "def morphs_nolab(activations, skip=2, last_layer=False):\n",
    "    #If last dimension is something other than 2, change it. otherwise 0.\n",
    "    trace_list = []\n",
    "    n_rows = 1 if ((len(activations)) < 10) else -(-len(activations)//10)\n",
    "    fig = tools.make_subplots(rows=n_rows, cols=(10))\n",
    "    last_dim = (2 if last_layer==False else 0)\n",
    "    for i in range(1, len(activations)):\n",
    "        #print((-(-i//10)), i%10, i-1, (i//2)+1)\n",
    "        #        fig.append_trace(go.Scatter(x=activations[i-1][:,0], y = activations[i-1][:,1] , mode='markers'), -(-i//10), (10 if i%10==0 else i%10))\n",
    "        temp_fig = ff.create_quiver(activations[i-1][:,0], activations[i-1][:,1], activations[i][:,0], activations[i][:,1],line=dict(width=1))\n",
    "        fig.append_trace(temp_fig['data'][0], -(-i//10), (10 if i%10==0 else i%10))\n",
    "    fig['layout'].update(height=n_rows*500)\n",
    "    fig['layout'].update(width=3500)\n",
    "    plot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the format of your plot grid:\n",
      "[ (1,1) x1,y1 ]     [ (1,2) x2,y2 ]     [ (1,3) x3,y3 ]     [ (1,4) x4,y4 ]     [ (1,5) x5,y5 ]     [ (1,6) x6,y6 ]     [ (1,7) x7,y7 ]     [ (1,8) x8,y8 ]     [ (1,9) x9,y9 ]     [ (1,10) x10,y10 ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "meshVelocities = []\n",
    "#meshVelocities.append(sess.run(x, feed_dict={x:mesh}))\n",
    "for layer in range(len(model.layers)):\n",
    "    extract_func = get_layer(0,layer, model)\n",
    "    meshVelocities.append(extract_func([mesh])[0])\n",
    "#print(len(meshVelocities))\n",
    "morphs_nolab(meshVelocities, skip=1, last_layer=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
